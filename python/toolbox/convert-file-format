#!/usr/bin/env python

import os
import sys
import time
import logging
import tracemalloc

# classes
from skyhookdm_singlecell.util import ArgparseBuilder
from skyhookdm_singlecell.parsers import GeneExpressionMatrixParser
from skyhookdm_singlecell.dataformats import (SkyhookGeneExpression, SkyhookFileWriter)


# Set-up logger
stdout_handler = logging.StreamHandler(sys.stdout)
stdout_handler.setFormatter(logging.Formatter(
    fmt='{levelname} <{name} | {asctime} ~> {message}',
    style='{'
))

analysis_logger = logging.getLogger('analysis')
analysis_logger.addHandler(logging.FileHandler('analysis.log'))
analysis_logger.setLevel(logging.DEBUG)

logger = logging.getLogger('toolbox.convert-file-format')
logger.setLevel(logging.DEBUG)
logger.addHandler(stdout_handler)

debug = False

# ------------------------------
# Parse command-line arguments first
parsed_args, parsed_extra_args = (
    ArgparseBuilder.with_description('Program for converting between specialized file formats')
                   .add_input_dir_arg(
                         required=True
                        ,help_str='Path to root directory of gene expression in MTX format'
                    )
                   .add_input_metadata_file_arg(
                         required=False
                        ,help_str='Path to file containing metadata'
                    )
                   .add_batch_args(
                         required=False
                        ,help_str='Number of records to batch together in output file'
                    )
                   .add_output_file_arg(
                         required=False
                        ,help_str='Path to file to write serialized data'
                    )
                   .add_output_file_format_arg(
                         required=True
                        ,help_str='File format for output files. Supports: "flatbuffer" | "parquet" | "arrow"'
                    )
                   .add_output_dir_arg(
                         required=False
                        ,help_str='Path to directory to write partitioned data in parquet format'
                    )
                   .add_data_format_arg(
                         required=False
                        ,help_str='Format of input data. Supports: "flatbuffer" | "arrow"'
                    )
                   .add_has_header_flag_arg(required=False)
                   .add_analysis_arg(required=False)
                   .add_flatbuffer_flag_arg(required=False)
                   .parse_args()
)


def start_analysis(flag_analysis):
    if not flag_analysis: return

    start_time = time.time()

    analysis_logger.info('Starting tracemalloc analysis.')
    analysis_logger.info(f'Start time: {start_time}')
    tracemalloc.start()

    return start_time


def snapshot_analysis(flag_analysis):
    if not flag_analysis: return

    snapshot_time = time.time()

    analysis_snapshot = tracemalloc.take_snapshot()
    analysis_logger.info(f'Snapshot time: {snapshot_time}')
    analysis_logger.info(analysis_snapshot.statistics('filename'))

    return snapshot_time


def stop_analysis(flag_analysis):
    if not flag_analysis: return

    stop_time = time.time()

    tracemalloc.stop()
    analysis_logger.info('Stopped tracemalloc analysis.')
    analysis_logger.info(f'Stop time: {stop_time}')

    return stop_time


# ------------------------------
if __name__ == '__main__':
    logger.debug('Parsed command-line arguments:\n{}'.format(
        '\n'.join([
            f'{arg_name}\t\t: {arg_val}'
            for arg_name, arg_val in vars(parsed_args).items()
        ])
    ))

    gene_expr            = None
    skyhook_expr_wrapper = None

    if parsed_args.data_format not in ('arrow',):
        error_msg = f'xxx Unsupported data format: {parsed_args.data_format}'
        logger.error(error_msg)
        sys.exit(error_msg)

    start_time = start_analysis(parsed_args.should_analyze)

    # ------------------------------
    # Parse input file

    if os.path.isdir(parsed_args.input_dir):
        logger.info('>>> parsing gene expression')

        gene_expr = GeneExpressionMatrixParser.gene_expr_from_dir(
            parsed_args.input_dir,
            has_header=parsed_args.flag_has_header
        )

        if debug:
            logger.debug('--- subsampling data to 100 genes and 20 cells')
            gene_expr.subsample_by_counts(gene_count=100, cell_count=20)

        logger.info('--- normalizing gene expression')
        gene_expr.normalize_expression()
        skyhook_expr_wrapper = SkyhookGeneExpression(gene_expr)

        logger.debug('--- gene expression shape: {}'.format(gene_expr.expression.shape))
        sample = gene_expr.expression[:3]

        try:
            logger.debug(sample[sample > 0])

        except Exception:
            logger.debug(f'Malformatted attempt to print non-zeros.\nsample: {sample}')

        logger.info('<<< gene expression parsed')

    # Log analysis after parsing the input file
    parse_time = snapshot_analysis(parsed_args.should_analyze)

    # ------------------------------
    # Write data in partitions
    if parsed_args.output_dir is not None:
        logger.info('>>> serializing cell expression')

        if not os.path.isdir(parsed_args.output_dir):
            os.makedirs(parsed_args.output_dir)

        if parsed_args.output_file_format == 'arrow':
            logger.info('--- writing in arrow binary format')
            SkyhookFileWriter.write_gene_expr_partitions_arrow(
                skyhook_expr_wrapper, parsed_args.output_dir, parsed_args.batch_size
            )

        elif parsed_args.output_file_format == 'parquet':
            logger.info('--- writing in parquet binary format')
            SkyhookFileWriter.write_gene_expr_partitions_parquet(
                skyhook_expr_wrapper, parsed_args.output_dir, parsed_args.batch_size
            )

        elif parsed_args.output_file_format == 'flatbuffer':
            logger.info('--- writing to flatbuffer binary file')

            # Place into a flatbuffer structure in specified data format
            if parsed_args.flag_use_wrapper and parsed_args.data_format == 'arrow':
                logger.info('--- serializing data in wrapped arrow format')

                SkyhookFileWriter.write_gene_expr_partitions_flatbuffer(
                    skyhook_expr_wrapper, parsed_args.output_dir, parsed_args.batch_size
                )

            elif not parsed_args.flag_use_wrapper and parsed_args.data_format == 'arrow':
                logger.info('--- serializing data in skyhook arrow format')

                SkyhookFileWriter.write_gene_expr_partitions_arrow(
                    skyhook_expr_wrapper, parsed_args.output_dir, parsed_args.batch_size
                )

        else:
            logger.error(f'Unknown file format: {parsed_args.output_file_format}')

        logger.info('<<< cell expression serialized')

    # ------------------------------
    # Write data in a single file
    if parsed_args.output_file is not None:
        logger.info('>>> serializing gene expression')

        if os.path.isfile(parsed_args.output_file):
            err_msg = 'Serialized file already exists. Finishing...'
            logger.error(err_msg)
            sys.exit(err_msg)

        if parsed_args.output_file.endswith('arrow'):
            SkyhookFileWriter.write_gene_expr_arrow(skyhook_expr_wrapper, parsed_args.output_file)

        elif parsed_args.output_file.endswith('parquet'):
            SkyhookFileWriter.write_gene_expr_parquet(skyhook_expr_wrapper, parsed_args.output_file)

        logger.info('<<< gene expression serialized')

    # Log analysis after writing output file(s)
    write_time = snapshot_analysis(parsed_args.should_analyze)
    stop_time  = stop_analysis(parsed_args.should_analyze)

    if parsed_args.should_analyze:
        elapsed_parse_time = parse_time - start_time
        elapsed_write_time = write_time - parse_time
        elapsed_total_time = stop_time  - start_time

        analysis_logger.info(f'Parse time (m): {elapsed_parse_time/60}')
        analysis_logger.info(f'Write time (m): {elapsed_write_time/60}')
        analysis_logger.info(f'Total time (m): {elapsed_total_time/60}')

        logger.info(f'Total time: {elapsed_total_time/60}')
